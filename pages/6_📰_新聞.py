# å¸‚å ´æ–°è â€” RSS æ‹‰å–åŠ å¯†è²¨å¹£ & è‚¡å¸‚æ–°è
import streamlit as st
import time
from datetime import datetime, timezone
from src.ui_common import apply_theme, breadcrumb, check_session, sidebar_user_nav

st.set_page_config(page_title="StocksX â€” å¸‚å ´æ–°è", page_icon="ğŸ“°", layout="wide")
apply_theme()
breadcrumb("å¸‚å ´æ–°è", "ğŸ“°")
sidebar_user_nav(check_session())
st.markdown("## ğŸ“° å¸‚å ´æ–°è")

NEWS_SOURCES = {
    "åŠ å¯†è²¨å¹£": [
        {"name": "CoinDesk", "url": "https://www.coindesk.com/arc/outboundfeeds/rss/", "icon": "â‚¿"},
        {"name": "CoinTelegraph", "url": "https://cointelegraph.com/rss", "icon": "ğŸ“¡"},
        {"name": "The Block", "url": "https://www.theblock.co/rss.xml", "icon": "ğŸ§±"},
        {"name": "Decrypt", "url": "https://decrypt.co/feed", "icon": "ğŸ”“"},
    ],
    "è‚¡ç¥¨ & è²¡ç¶“": [
        {"name": "Yahoo Finance", "url": "https://finance.yahoo.com/news/rssindex", "icon": "ğŸ“ˆ"},
        {"name": "MarketWatch", "url": "https://feeds.marketwatch.com/marketwatch/topstories/", "icon": "ğŸ‘ï¸"},
        {"name": "CNBC", "url": "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=100003114", "icon": "ğŸ“º"},
    ],
}


@st.cache_data(ttl=600, show_spinner=False)
def _fetch_rss(url: str, max_items: int = 15) -> list[dict]:
    """æ‹‰å– RSS ä¸¦è§£æ"""
    try:
        import xml.etree.ElementTree as ET
        import urllib.request
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = resp.read()
        root = ET.fromstring(data)
        items = []
        for item in root.iter("item"):
            title = item.findtext("title", "")
            link = item.findtext("link", "")
            pub_date = item.findtext("pubDate", "")
            desc = item.findtext("description", "")
            if desc and len(desc) > 200:
                desc = desc[:200] + "â€¦"
            for tag in ["<p>", "</p>", "<br>", "<br/>", "<img", "<a "]:
                if tag in desc:
                    desc = ""
                    break
            items.append({"title": title, "link": link, "date": pub_date, "desc": desc})
            if len(items) >= max_items:
                break
        return items
    except urllib.request.URLError as e:
        return [{"title": f"âš ï¸ ç¶²è·¯é€£ç·šå¤±æ•—: {str(e.reason)[:50]}", "link": "", "date": "", "desc": "è«‹æª¢æŸ¥ç¶²è·¯é€£ç·š"}]
    except ET.ParseError:
        return [{"title": "âš ï¸ RSS æ ¼å¼è§£æå¤±æ•—", "link": "", "date": "", "desc": "ä¾†æºå¯èƒ½å·²è®Šæ›´æ ¼å¼"}]
    except Exception as e:
        return [{"title": f"âš ï¸ è¼‰å…¥å¤±æ•—: {str(e)[:60]}", "link": "", "date": "", "desc": ""}]


tab_names = list(NEWS_SOURCES.keys())
tabs = st.tabs([f"{list(NEWS_SOURCES[k])[0]['icon']} {k}" for k in tab_names])

for tab, cat_name in zip(tabs, tab_names):
    with tab:
        sources = NEWS_SOURCES[cat_name]
        source_names = [s["name"] for s in sources]
        selected = st.selectbox("æ–°èä¾†æº", source_names, key=f"src_{cat_name}")
        source = next(s for s in sources if s["name"] == selected)

        with st.spinner(f"è¼‰å…¥ {selected} æ–°èâ€¦"):
            articles = _fetch_rss(source["url"])

        if articles:
            for a in articles:
                if not a["title"] or "è¼‰å…¥å¤±æ•—" in a["title"]:
                    st.warning(a["title"])
                    continue
                col1, col2 = st.columns([5, 1])
                with col1:
                    if a["link"]:
                        st.markdown(f"**[{a['title']}]({a['link']})**")
                    else:
                        st.markdown(f"**{a['title']}**")
                    if a["desc"]:
                        st.caption(a["desc"])
                with col2:
                    if a["date"]:
                        st.caption(a["date"][:16])
                st.divider()
        else:
            st.info("æš«ç„¡æ–°è")

st.caption("ğŸ“¡ æ–°èæ¯ 10 åˆ†é˜è‡ªå‹•åˆ·æ–° | ä¾†æºï¼šCoinDesk, CoinTelegraph, Yahoo Finance, CNBC ç­‰")
